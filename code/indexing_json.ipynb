{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing of Documents used for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 reports from ahava_env.json\n",
      "Loaded 3 reports from ahava_ethics.json\n",
      "Loaded 2 reports from ahava_info.json\n",
      "Loaded 4 reports from avon_env.json\n",
      "Loaded 2 products from avon_env.json\n",
      "Loaded 3 reports from avon_ethics.json\n",
      "Loaded 2 products from avon_ethics.json\n",
      "Loaded 3 reports from avon_info.json\n",
      "Loaded 2 products from avon_info.json\n",
      "Loaded 7 reports from cerave_env.json\n",
      "Loaded 6 reports from cerave_ethics.json\n",
      "Loaded 5 reports from cerave_info.json\n",
      "Loaded 3 reports from darphin_env.json\n",
      "Loaded 3 reports from darphin_ethics.json\n",
      "Loaded 3 reports from darphin_info.json\n",
      "Loaded 3 reports from delia_cosmetics_env.json\n",
      "Loaded 3 reports from delia_cosmetics_ethics.json\n",
      "Loaded 3 reports from delia_cosmetics_info.json\n",
      "Loaded 4 reports from estee_lauder_env.json\n",
      "Loaded 4 reports from estee_lauder_ethics.json\n",
      "Loaded 4 reports from estee_lauder_info.json\n",
      "Loaded 4 reports from korres_env.json\n",
      "Loaded 4 reports from korres_ethics.json\n",
      "Loaded 3 reports from korres_info.json\n",
      "Loaded 3 reports from lumene_env.json\n",
      "Loaded 3 reports from lumene_ethics.json\n",
      "Loaded 3 reports from lumene_info.json\n",
      "Loaded 3 reports from missah_env.json\n",
      "Loaded 3 reports from missah_ethics.json\n",
      "Loaded 3 reports from missah_info.json\n",
      "Loaded 3 reports from mixa_env.json\n",
      "Loaded 3 reports from mixa_ethics.json\n",
      "Loaded 3 reports from mixa_info.json\n",
      "Loaded 3 reports from nuxe_env.json\n",
      "Loaded 2 reports from nuxe_ethics.json\n",
      "Loaded 2 reports from nuxe_info.json\n",
      "Loaded 5 reports from peter_thomas_roth_env.json\n",
      "Loaded 5 reports from peter_thomas_roth_ethics.json\n",
      "Loaded 4 reports from peter_thomas_roth_info.json\n",
      "Loaded 4 reports from shiseido_env.json\n",
      "Loaded 3 reports from shiseido_ethics.json\n",
      "Loaded 2 reports from shiseido_info.json\n",
      "Loaded 7 reports from some_by_mi_env.json\n",
      "Loaded 6 reports from some_by_mi_ethics.json\n",
      "Loaded 5 reports from some_by_mi_info.json\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_core.documents.base import Document\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# set parameters\n",
    "#---------------------------------------------------------------------------------------\n",
    "# general parameters\n",
    "rag_docs_folder = \"Rag_docs\" # folder containing json files to be loaded\n",
    "\n",
    "# test splitter parameters\n",
    "chunk_size = 1000 # chunk size for splitting documents\n",
    "chunk_overlap = 200 # chunk overlap for splitting documents\n",
    "add_start_index = True # whether to track index in original document\n",
    "\n",
    "# Qdrant parameters\n",
    "min_len = 20 # minimum length of documents to be stored in Qdrant\n",
    "collection_name = \"demo_collection\" # name of the Qdrant collection\n",
    "db_path = \"test_rag_db\" # path to the Qdrant database\n",
    "distance = Distance.COSINE # distance metric for Qdrant\n",
    "\n",
    "# embedding model parameters\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\" # embedding model name\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# get pdf files from Rag_docs folder \n",
    "paths = [path for path in os.listdir(rag_docs_folder) if path.endswith(\".json\")]\n",
    "\n",
    "# list of docs, metadata and ids to store in Qdrant\n",
    "docs = []\n",
    "ids = []\n",
    "\n",
    "# text splitter to split documents into smaller chunks for retrieval\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,  # chunk size (characters)\n",
    "    chunk_overlap=chunk_overlap,  # chunk overlap (characters)\n",
    "    add_start_index=add_start_index,  # track index in original document\n",
    "    )\n",
    "\n",
    "# load and process json files using PyPDFLoader\n",
    "for path in paths:\n",
    "    with open(rag_docs_folder + \"\\\\\" + path) as f:\n",
    "        text = json.load(f)\n",
    "\n",
    "    text_to_embed = text[\"report\"] #+ str(text[\"products\"]) if \"products\" in text else text[\"report\"]\n",
    "    # split texts into smaller chunks\n",
    "    text_chunks = text_splitter.split_text(text_to_embed)\n",
    "\n",
    "    # only add texts to list that are longer than min_len characters, creating a Document object for each chunk and adding metadata\n",
    "    docs_min_length = [Document(d, metadata={\"company\": text[\"company\"],\"topic\": text[\"topic\"],\"source_file\": path, \"report\":\"\"}) for d in text_chunks if len(d) > min_len]\n",
    "\n",
    "    # add documents containing text and metadata to lists for Qdrant upload\n",
    "    docs.extend(docs_min_length)\n",
    "\n",
    "    print(f\"Loaded {len(docs_min_length)} reports from {path}\")\n",
    "\n",
    "    # add products as documents to Qdrant\n",
    "    if \"products\" in text:\n",
    "        # create a Document object for each product and add metadata\n",
    "        docs_procuts = [Document(str(product), metadata={\"company\": text[\"company\"],\"topic\": text[\"topic\"],\"source_file\": path, \"report\":text[\"report\"]}) for product in text[\"products\"]]\n",
    "        docs.extend(docs_procuts)\n",
    "\n",
    "        print(f\"Loaded {len(docs_procuts)} products from {path}\")\n",
    "\n",
    "ids = [i for i in range(len(docs))]\n",
    "\n",
    "# embedding model to convert text to vectors\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "# Initialize the Qdrant client with a local path\n",
    "client = QdrantClient(path=db_path)\n",
    "\n",
    "try:\n",
    "    if not client.collection_exists(collection_name):\n",
    "        # create a new collection if it doesn't exist\n",
    "\n",
    "        vector_length = len(embeddings.embed_documents([\"dummy\"])[0])  # get vector length from dummy embedding\n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=VectorParams(size=vector_length, distance=distance),\n",
    "        )\n",
    "\n",
    "    vector_store = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=embeddings,\n",
    "    )\n",
    "\n",
    "    _ = vector_store.add_documents(docs, ids=ids) # metadata is contained in the documents\n",
    "finally:\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
